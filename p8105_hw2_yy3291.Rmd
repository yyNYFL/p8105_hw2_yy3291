---
title: "Homework 2"
author: "Youssra Yemmas"
date: "2023-10-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(here)
library(readr)
```


## Problem 1

```{r}
# first need to create a month data frame so that the mon variable can be broken up into 3 integer variables of month day and year

month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

# I need to figure out a good relative path for my files using the here package

here()
here::here("pols-month.csv")

# Now I will read the pols-month data, use the separate function to break up the mon variable and replace month number with month name. I also removed the prez_gop and prez_dem vriables and replaced them with a president variable with values 0 to represent dem and 1 and 2 to represent gop. 

pols = 
  readr::read_csv(
    here("pols-month.csv")) |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez"))

# I will read in the snp data and clean it to match the pols dataframe 

snp = 
  readr::read_csv(
    here("snp.csv"),
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 

# Tidying the unemployment dataset to match the other two so that they can all be merged together.

unemployment = 
  readr::read_csv(
    here("unemployment.csv")) |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)

# Finally merging the three datasets into one data set titled data_538 
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
view(data_538)
summary(pols)
summary(snp)
summary(unemployment)
summary(data_538)
```

### The combined dataset, data_538, has merged the pols data, which provides information on the number of national politicians who are democratic or republican at any given time, the snp data, which is related to Standard & Poorâ€™s stock market index (S&P), often used as a representative measure of stock market as a whole, and the unemployment data which contains information on the percentage of unemployment in a given month of an assocaited year. The first thing I notice upon viewing the data is that there are quite a few NA's or missing variables in the variables close and unemployment (36 and 12 respectively). In the snp data frame there are 787 observations of 3 variables and the year vriable contains values from 1950 to 2015 and the close variables which represents the closing values of the S&P stock index at a given data has a min of 17.05 a median of 138.53 and a max of 2107.39. The pols datafram has 822 observations of 11 variables with data from the years 1947 to 2015. The unemployment data frame has 816 observations of 3 variables with data from the years 1948 to 2015. The data shows a minimum unemployment percentage of 2.5 and a maximum of 10.8. The combined data set, data_538 has 822 observations of 13 variables with data from the years 1947 to 2015.

# Problem 2

```{r}
# Here I am reading the excel file that contains the data on Mr Trash Can dumpster. I am using the arguments in read_excel specifically range to exclude the two columns 15 and 16 that contain irrelevant notes, I am also using the range argument to exclude the bottom row that contains summary figures. 
mr_trash_wheel = 
  readxl::read_excel(
    here("Mr Trash Wheel.xlsx"), sheet = NULL, range = "A2:N586", col_names = TRUE, col_types = NULL, na = "NA",   trim_ws = TRUE) 
mr_trash_wheel = janitor::clean_names(mr_trash_wheel)

# Here I am fixing the homes_powered variable so that it is applied ot every row in the dataset because before there were many 0's. From the Homes powered note that states each ton of trash equates to on average 500 kilowatts of electricity.  An average household will use 30 kilowatts per day.I took that to mean I must take the weight in tons variable that the dumpster collects multiply that by 500 and divide it by 30 to find the number of Homes powered by each dumpster.
mr_trash_wheel =
  mutate(
    mr_trash_wheel, homes_powered = (weight_tons*500)/30)



# I am using a similar process as I detailed above to import, clean and organize the data for the Gwynda Trash Wheel. One difference though is the fact that the homes_powered variable in this data frame is correct and applied for all rows in the data frame unlike in Mr Trash Wheel. 
gwynda_trash_wheel = 
  readxl::read_excel(
    here("Gwynda Trash Wheel.xlsx"), sheet = NULL, range = "A2:L157", col_names = TRUE, col_types = NULL, na = "NA",   trim_ws = TRUE) 
gwynda_trash_wheel = janitor::clean_names(gwynda_trash_wheel)

#Just to be safe though I will be applying the same mutate argument to the homes_powered variables.

gwynda_trash_wheel =
  mutate(
    gwynda_trash_wheel, homes_powered = (weight_tons*500)/30)


# Lastly I will follow the same process for Professor Trash Wheel

professor_trash_wheel = 
  readxl::read_excel(
    here("Professor Trash Wheel.xlsx"), sheet = NULL, range = "A2:M108", col_names = TRUE, col_types = NULL, na = "NA",   trim_ws = TRUE) 
professor_trash_wheel = janitor::clean_names(professor_trash_wheel) |>
  mutate(
    professor_trash_wheel, homes_powered = (weight_tons*500)/30)

summary(mr_trash_wheel)
summary(gwynda_trash_wheel)
summary(professor_trash_wheel)
sum(professor_trash_wheel$weight_tons)
#The total weight of trash collected by Professor Trash Wheel for all available data was 216.26 tons. 
sum_cb <- filter(gwynda_trash_wheel, year == 2021, month == "July")
sum(sum_cb$cigarette_butts)
# In July of 2021 the total number of cigarette bitts collected by the Gwynnda Trash Wheel was 163,000.

#Adding a new variable to each dataset to indicate which trash wheel it is coming from which may come in handy when trying to merge the datasets into on large one. I am using 1 to refer to Mr Trash, 2 to refer to Gywnda and 3 to refer to Professor 
mr_trash_wheel =
  mutate(
    mr_trash_wheel, trash_wheel = 1)

gwynda_trash_wheel = 
  mutate(
    gwynda_trash_wheel, trash_wheel = 2
  )

professor_trash_wheel = 
  mutate(
    professor_trash_wheel, trash_wheel = 3
  )
is.numeric(professor_trash_wheel$year)

wheels_tidy = 
 left_join(gwynda_trash_wheel, professor_trash_wheel, by = join_by("dumpster")) |>
  right_join(x = _, y = mr_trash_wheel, by = join_by("dumpster"))

view(wheels_tidy)
summary(wheels_tidy)
```

### The combined data set resulted 585 observations of 40 variables.The years for the data range from 1900 to 2023. The weight in tons of garbage the dumpsters have collected range from a minimum of 0.770 tons to 4.180 tons. One interesting statistics was that a max number of homes powered by an amount of garbage a trash wheel has collected went as high as 93 homes. 

# Problem 3
```{r}
# I will need to first import the dataset of baseline demographics. I need to first do a relative file path using the here function

here::here("MCI_baseline.csv")
mci_baseline =
  readr::read_csv(
    here("MCI_baseline.csv"), skip = 1, col_names = TRUE, na = ".", col_types = cols(
      ID = col_character(),
      "Current Age" = col_double(),
      "Sex" = col_character(),
      "Education" = col_double(),
      "apoe4" = col_character(),
      "Age at onset" = col_number()
    )
  )
## doint this make the names ugly so i need to get rid of it mci_baseline =
  #janitor::clean_names(mci_baseline)

# From viewing the dataset I notice that the variables sex and AP0E4 are not properly encoded so I will need to change that. I also need to look at the data more to see if anything else should be done so I will be doing that using the skimr package

skimr::skim(mci_baseline)
is.character(mci_baseline$Sex)
is.character(mci_baseline$apoe4)
filter(mci_baseline, apoe4 == 1)
filter(mci_baseline, Sex == 0, apoe4 == 1)
filter(mci_baseline, Sex == 0)
63/211
median(mci_baseline$`Age at onset`)
# I can see from the above code that I now the variables sex and APOE4 are encoded as character variables rather than numeric. There are 483 observations of the 6 variables which means that there are 483 participants that have been recruited. Using the filter function I can see that of the participants recruited 145 of them are carrier for apoe4 variant. There are 211 women and 63 of those women are apoe4 carriers which is a proportion of about 0.3.


# I will be using a similar process to import, read and tidy the data for the mci amyloid data of longitudinally observed biomarker values

here::here("mci_amyloid.csv")
mci_amyloid =
  readr::read_csv(
    here("mci_amyloid.csv"), skip = 1, col_names = TRUE, na = "NA", col_types = cols(
      "Study ID" = col_character(),
      "Baseline" = col_double(),
      "Time 2" = col_double(),
      "Time 4" = col_double(),
      "Time 6" = col_double(),
      "Time 8" = col_double()
    )
    )

skimr::skim(mci_amyloid)

# This data set has longitudinal measures of biomarkers so it has the baseline measure and then follows the same individuals over 4 time periods. Looking at the medians of the baseline and then each time period using the skim function I can see that the biomarker levels decrease slightly over time-going from 0.111 to 0.110 to 0.109 and 0.108 but this is very subtle. If study ID number being the same across both datasets indicates it is the same participants than we can see that the first 483 participants in the mci_baseline dataset are in common with the mci_amyloid dataset.

# I will be merging the two datasets 
mci_amyloid <- mci_amyloid |>
  rename("ID" = "Study ID")
mci_total = 
  left_join(mci_baseline, mci_amyloid, by = join_by("ID"))

summary(mci_total)
# I have the resultant dataset titled mci_total it contains 483 observations and 11 variables. The Minimum age is 56 and the Maximum age is 72.9, the minimum years of education is 12 with the maximum being 20 and the minimum age of onset is 61.2. 

```

# Saving the total dataframe
```{r}
readr::write_csv(mci_total, file = "mci_total.csv")
```

